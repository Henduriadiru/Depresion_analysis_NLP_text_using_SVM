{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dc58b60-4abc-4f2e-b5a7-4bed56d03f2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-10 14:20:37.986 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2025-04-10 14:20:38.002 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2025-04-10 14:20:38.002 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-10 14:20:38.853 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\Thinkpad\\.julia\\conda\\3\\x86_64\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-04-10 14:20:38.853 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-10 14:20:38.853 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-10 14:20:39.000 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-10 14:20:39.008 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-10 14:20:39.008 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-10 14:20:39.008 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-10 14:20:39.008 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-10 14:20:39.008 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-10 14:20:39.008 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-10 14:20:39.023 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-10 14:20:39.055 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-10 14:20:39.055 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-10 14:20:39.055 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-10 14:20:39.576 Thread 'Thread-6': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-10 14:20:39.576 Thread 'Thread-6': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-10 14:21:05.703 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-10 14:21:05.703 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 45\u001b[0m\n\u001b[0;32m     42\u001b[0m     X_tsne \u001b[38;5;241m=\u001b[39m tsne\u001b[38;5;241m.\u001b[39mfit_transform(X_pca)\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model, X_pca, X_tsne\n\u001b[1;32m---> 45\u001b[0m model, X_pca, X_tsne \u001b[38;5;241m=\u001b[39m train_model(df)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Tabs for visualization and prediction\u001b[39;00m\n\u001b[0;32m     48\u001b[0m visual_tab, predict_tab \u001b[38;5;241m=\u001b[39m st\u001b[38;5;241m.\u001b[39mtabs([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mðŸ“ˆ Visualization\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mðŸ§  Predict Sentiment\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32m~\\.julia\\conda\\3\\x86_64\\Lib\\site-packages\\streamlit\\runtime\\caching\\cache_utils.py:219\u001b[0m, in \u001b[0;36mCachedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    217\u001b[0m         spinner_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m(...)`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 219\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_or_create_cached_value(args, kwargs, spinner_message)\n",
      "File \u001b[1;32m~\\.julia\\conda\\3\\x86_64\\Lib\\site-packages\\streamlit\\runtime\\caching\\cache_utils.py:261\u001b[0m, in \u001b[0;36mCachedFunc._get_or_create_cached_value\u001b[1;34m(self, func_args, func_kwargs, spinner_message)\u001b[0m\n\u001b[0;32m    255\u001b[0m spinner_or_no_context \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    256\u001b[0m     spinner(spinner_message, _cache\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    257\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m spinner_message \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_nested_cache_function\n\u001b[0;32m    258\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext()\n\u001b[0;32m    259\u001b[0m )\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m spinner_or_no_context:\n\u001b[1;32m--> 261\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_cache_miss(cache, value_key, func_args, func_kwargs)\n",
      "File \u001b[1;32m~\\.julia\\conda\\3\\x86_64\\Lib\\site-packages\\streamlit\\runtime\\caching\\cache_utils.py:320\u001b[0m, in \u001b[0;36mCachedFunc._handle_cache_miss\u001b[1;34m(self, cache, value_key, func_args, func_kwargs)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;66;03m# We acquired the lock before any other thread. Compute the value!\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mcached_message_replay_ctx\u001b[38;5;241m.\u001b[39mcalling_cached_function(\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfunc\n\u001b[0;32m    319\u001b[0m ):\n\u001b[1;32m--> 320\u001b[0m     computed_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39mfunc_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfunc_kwargs)\n\u001b[0;32m    322\u001b[0m \u001b[38;5;66;03m# We've computed our value, and now we need to write it back to the cache\u001b[39;00m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;66;03m# along with any \"replay messages\" that were generated during value computation.\u001b[39;00m\n\u001b[0;32m    324\u001b[0m messages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mcached_message_replay_ctx\u001b[38;5;241m.\u001b[39m_most_recent_messages\n",
      "Cell \u001b[1;32mIn[3], line 42\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     40\u001b[0m X_pca \u001b[38;5;241m=\u001b[39m pca\u001b[38;5;241m.\u001b[39mfit_transform(X_vectors)\n\u001b[0;32m     41\u001b[0m tsne \u001b[38;5;241m=\u001b[39m TSNE(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 42\u001b[0m X_tsne \u001b[38;5;241m=\u001b[39m tsne\u001b[38;5;241m.\u001b[39mfit_transform(X_pca)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model, X_pca, X_tsne\n",
      "File \u001b[1;32m~\\.julia\\conda\\3\\x86_64\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:319\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 319\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    322\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    323\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    324\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    325\u001b[0m         )\n",
      "File \u001b[1;32m~\\.julia\\conda\\3\\x86_64\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\.julia\\conda\\3\\x86_64\\Lib\\site-packages\\sklearn\\manifold\\_t_sne.py:1178\u001b[0m, in \u001b[0;36mTSNE.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1175\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params_vs_input(X)\n\u001b[1;32m-> 1178\u001b[0m embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X)\n\u001b[0;32m   1179\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_ \u001b[38;5;241m=\u001b[39m embedding\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_\n",
      "File \u001b[1;32m~\\.julia\\conda\\3\\x86_64\\Lib\\site-packages\\sklearn\\manifold\\_t_sne.py:1046\u001b[0m, in \u001b[0;36mTSNE._fit\u001b[1;34m(self, X, skip_num_points)\u001b[0m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;66;03m# Degrees of freedom of the Student's t-distribution. The suggestion\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;66;03m# degrees_of_freedom = n_components - 1 comes from\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;66;03m# \"Learning a Parametric Embedding by Preserving Local Structure\"\u001b[39;00m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;66;03m# Laurens van der Maaten, 2009.\u001b[39;00m\n\u001b[0;32m   1044\u001b[0m degrees_of_freedom \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m-> 1046\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tsne(\n\u001b[0;32m   1047\u001b[0m     P,\n\u001b[0;32m   1048\u001b[0m     degrees_of_freedom,\n\u001b[0;32m   1049\u001b[0m     n_samples,\n\u001b[0;32m   1050\u001b[0m     X_embedded\u001b[38;5;241m=\u001b[39mX_embedded,\n\u001b[0;32m   1051\u001b[0m     neighbors\u001b[38;5;241m=\u001b[39mneighbors_nn,\n\u001b[0;32m   1052\u001b[0m     skip_num_points\u001b[38;5;241m=\u001b[39mskip_num_points,\n\u001b[0;32m   1053\u001b[0m )\n",
      "File \u001b[1;32m~\\.julia\\conda\\3\\x86_64\\Lib\\site-packages\\sklearn\\manifold\\_t_sne.py:1098\u001b[0m, in \u001b[0;36mTSNE._tsne\u001b[1;34m(self, P, degrees_of_freedom, n_samples, X_embedded, neighbors, skip_num_points)\u001b[0m\n\u001b[0;32m   1095\u001b[0m \u001b[38;5;66;03m# Learning schedule (part 1): do 250 iteration with lower momentum but\u001b[39;00m\n\u001b[0;32m   1096\u001b[0m \u001b[38;5;66;03m# higher learning rate controlled via the early exaggeration parameter\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m P \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mearly_exaggeration\n\u001b[1;32m-> 1098\u001b[0m params, kl_divergence, it \u001b[38;5;241m=\u001b[39m _gradient_descent(obj_func, params, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mopt_args)\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[t-SNE] KL divergence after \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m iterations with early exaggeration: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1102\u001b[0m         \u001b[38;5;241m%\u001b[39m (it \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, kl_divergence)\n\u001b[0;32m   1103\u001b[0m     )\n",
      "File \u001b[1;32m~\\.julia\\conda\\3\\x86_64\\Lib\\site-packages\\sklearn\\manifold\\_t_sne.py:401\u001b[0m, in \u001b[0;36m_gradient_descent\u001b[1;34m(objective, p0, it, max_iter, n_iter_check, n_iter_without_progress, momentum, learning_rate, min_gain, min_grad_norm, verbose, args, kwargs)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;66;03m# only compute the error when needed\u001b[39;00m\n\u001b[0;32m    399\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompute_error\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m check_convergence \u001b[38;5;129;01mor\u001b[39;00m i \u001b[38;5;241m==\u001b[39m max_iter \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 401\u001b[0m error, grad \u001b[38;5;241m=\u001b[39m objective(p, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    403\u001b[0m inc \u001b[38;5;241m=\u001b[39m update \u001b[38;5;241m*\u001b[39m grad \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m    404\u001b[0m dec \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39minvert(inc)\n",
      "File \u001b[1;32m~\\.julia\\conda\\3\\x86_64\\Lib\\site-packages\\sklearn\\manifold\\_t_sne.py:282\u001b[0m, in \u001b[0;36m_kl_divergence_bh\u001b[1;34m(params, P, degrees_of_freedom, n_samples, n_components, angle, skip_num_points, verbose, compute_error, num_threads)\u001b[0m\n\u001b[0;32m    279\u001b[0m indptr \u001b[38;5;241m=\u001b[39m P\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mint64, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    281\u001b[0m grad \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(X_embedded\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m--> 282\u001b[0m error \u001b[38;5;241m=\u001b[39m _barnes_hut_tsne\u001b[38;5;241m.\u001b[39mgradient(\n\u001b[0;32m    283\u001b[0m     val_P,\n\u001b[0;32m    284\u001b[0m     X_embedded,\n\u001b[0;32m    285\u001b[0m     neighbors,\n\u001b[0;32m    286\u001b[0m     indptr,\n\u001b[0;32m    287\u001b[0m     grad,\n\u001b[0;32m    288\u001b[0m     angle,\n\u001b[0;32m    289\u001b[0m     n_components,\n\u001b[0;32m    290\u001b[0m     verbose,\n\u001b[0;32m    291\u001b[0m     dof\u001b[38;5;241m=\u001b[39mdegrees_of_freedom,\n\u001b[0;32m    292\u001b[0m     compute_error\u001b[38;5;241m=\u001b[39mcompute_error,\n\u001b[0;32m    293\u001b[0m     num_threads\u001b[38;5;241m=\u001b[39mnum_threads,\n\u001b[0;32m    294\u001b[0m )\n\u001b[0;32m    295\u001b[0m c \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2.0\u001b[39m \u001b[38;5;241m*\u001b[39m (degrees_of_freedom \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1.0\u001b[39m) \u001b[38;5;241m/\u001b[39m degrees_of_freedom\n\u001b[0;32m    296\u001b[0m grad \u001b[38;5;241m=\u001b[39m grad\u001b[38;5;241m.\u001b[39mravel()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "# Load data (for demo, replace this with actual data path)\n",
    "@st.cache_data\n",
    "def load_data():\n",
    "    # Sample data loading, replace with your real dataset\n",
    "    df = pd.read_csv(\"sample_depresion_analysis.csv\")  # make sure the CSV contains 'tweet', 'cleaned_tweet', and 'label'\n",
    "    return df\n",
    "\n",
    "df = load_data()\n",
    "\n",
    "st.title(\"ðŸ“Š Depression Text Analysis App\")\n",
    "st.write(\"This app performs PCA/t-SNE visualization and predicts depression sentiment from input text.\")\n",
    "\n",
    "# Train Word2Vec model and PCA\n",
    "@st.cache_resource\n",
    "def train_model(df):\n",
    "    model = Word2Vec(df[\"cleaned_tweet\"], vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "    def text_to_vector(clean_text):\n",
    "        vectors = [model.wv[token] for token in clean_text if token in model.wv]\n",
    "        if len(vectors) == 0:\n",
    "            return np.zeros(model.vector_size)\n",
    "        return np.mean(vectors, axis=0)\n",
    "\n",
    "    X_vectors = np.array([text_to_vector(tokens) for tokens in df[\"cleaned_tweet\"]])\n",
    "    pca = PCA(n_components=50)\n",
    "    X_pca = pca.fit_transform(X_vectors)\n",
    "\n",
    "    # Sample only 1000 rows to speed up t-SNE\n",
    "    sample_size = min(1000, len(X_pca))\n",
    "    sample_idx = np.random.choice(len(X_pca), size=sample_size, replace=False)\n",
    "    tsne = TSNE(n_components=2, random_state=42, perplexity=30, n_iter=500)\n",
    "    X_tsne = tsne.fit_transform(X_pca[sample_idx])\n",
    "    labels_sampled = df.iloc[sample_idx][\"label\"].values\n",
    "\n",
    "    return model, X_pca, X_tsne, labels_sampled\n",
    "\n",
    "model, X_pca, X_tsne, labels_sampled = train_model(df)\n",
    "\n",
    "# Tabs for visualization and prediction\n",
    "visual_tab, predict_tab = st.tabs([\"ðŸ“ˆ Visualization\", \"ðŸ§  Predict Sentiment\"])\n",
    "\n",
    "with visual_tab:\n",
    "    plot_type = st.selectbox(\"Choose a plot\", [\"PCA\", \"t-SNE\"])\n",
    "    if plot_type == \"PCA\":\n",
    "        fig, ax = plt.subplots(figsize=(8, 5))\n",
    "        scatter = ax.scatter(X_pca[:, 0], X_pca[:, 1], c=df['label'], cmap='viridis')\n",
    "        ax.set_title(\"PCA Visualisation\")\n",
    "        st.pyplot(fig)\n",
    "    else:\n",
    "        fig, ax = plt.subplots(figsize=(8, 5))\n",
    "        scatter = ax.scatter(X_tsne[:, 0], X_tsne[:, 1], c=labels_sampled, cmap='viridis')\n",
    "        ax.set_title(\"t-SNE Visualisation (Sampled)\")\n",
    "        st.pyplot(fig)\n",
    "\n",
    "with predict_tab:\n",
    "    user_input = st.text_area(\"Enter a tweet or sentence to analyze:\")\n",
    "\n",
    "    if user_input:\n",
    "        import re\n",
    "        from nltk.corpus import stopwords\n",
    "        from nltk.tokenize import word_tokenize\n",
    "\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "\n",
    "        def clean_and_tokenize(text):\n",
    "            text = re.sub(r\"[^a-zA-Z]\", \" \", text.lower())\n",
    "            tokens = word_tokenize(text)\n",
    "            return [word for word in tokens if word not in stop_words]\n",
    "\n",
    "        cleaned = clean_and_tokenize(user_input)\n",
    "        vector = np.mean([model.wv[token] for token in cleaned if token in model.wv] or [np.zeros(model.vector_size)], axis=0)\n",
    "\n",
    "        # Dummy classifier (replace with trained SVM or load from pickle)\n",
    "        st.warning(\"Note: This is a dummy prediction. Replace with a trained classifier.\")\n",
    "        dummy_label = int(np.random.choice([0, 1]))\n",
    "        st.write(\"Predicted Label:\", \"Depressed\" if dummy_label == 1 else \"Not Depressed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d282f7f7-bbc0-42a4-8312-9a22886e8d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'streamlit_depresion_analysis_text.py'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490dbe37-5714-4b10-9110-a84962ca7d0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
